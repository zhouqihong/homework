{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyltp import Segmentor # pyltp 提供分词、词性标注、命名实体识别、依存句法分析、语义角色标注等功能。\n",
    "from pyltp import SentenceSplitter\n",
    "from pyltp import Postagger\n",
    "from pyltp import NamedEntityRecognizer\n",
    "from pyltp import Parser\n",
    "#from get_synonyms import load_synonyms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(string): # 分句\n",
    "    sen = SentenceSplitter.split(string)\n",
    "    sentences = [s for s in sen if len(s) != 0]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(string): # 分词\n",
    "    LTP_DATA_DIR = 'D:/NLP/ltp_data_v3.4.0' # Ltp模型目录的路径\n",
    "    cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model') # 分词模型路径，分词模型名称是‘cws.model’\n",
    "    \n",
    "    segmentor = Segmentor()\n",
    "    segmentor.load(cws_model_path)\n",
    "    words = segmentor.segment(string)\n",
    "    segmentor.release()\n",
    "    \n",
    "    #print('\\t'.join(words))\n",
    "    \n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_pos(words): # words分词后的\n",
    "    LTP_DATA_DIR = 'D:/NLP/ltp_data_v3.4.0' # Ltp模型目录的路径\n",
    "    pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model') # 词性标注模型路径，分词模型名称是‘pos.model’\n",
    "    \n",
    "    postagger = Postagger()\n",
    "    postagger.load(pos_model_path)\n",
    "    \n",
    "    postags = postagger.postag(words)\n",
    "    postagger.release()\n",
    "    \n",
    "    #print('\\t'.join(postags))\n",
    "    \n",
    "    return list(postags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(words, postags): # 命名实体识别\n",
    "    LTP_DATA_DIR = 'D:/NLP/ltp_data_v3.4.0'\n",
    "    ner_model_path = os.path.join(LTP_DATA_DIR, 'ner.model')\n",
    "    \n",
    "    recognizer = NamedEntityRecognizer()\n",
    "    recognizer.load(ner_model_path)\n",
    "    \n",
    "    netags = recognizer.recognize(words, postags)\n",
    "    recognizer.release()\n",
    "    \n",
    "    #print('\\t'.join(netags))\n",
    "    \n",
    "    return list(netags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dependency_parsing(words, postags): # 依存句法分析\n",
    "    LTP_DATA_DIR = 'D:/NLP/ltp_data_v3.4.0'\n",
    "    par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')\n",
    "    \n",
    "    parser = Parser()\n",
    "    parser.load(par_model_path)\n",
    "    \n",
    "    arcs = parser.parse(words, postags) # 句法分析\n",
    "    parser.release()\n",
    "    \n",
    "    #print(\"\\t\".join(\"%d: %s\" % (arc.head, arc.relation) for arc in arcs))\n",
    "    \n",
    "    return list(arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_say_what(sentence): # 对单句提取新闻人物和言论\n",
    "    \n",
    "    content = list()\n",
    "    say = ['说','告诉','讲','表示','回应','呼吁','指出']\n",
    "    #say = load_synonyms('synonyms.txt')\n",
    "    \n",
    "    words = split_words(sentence)\n",
    "    postags = get_sentence_pos(words)\n",
    "    netags = NER(words, postags)\n",
    "    \n",
    "    if any(x in netags for x in ['S-Nh', 'S-Ni', 'S-Ns']): # If the sentence contains someone's saying\n",
    "        arcs = dependency_parsing(words, postags)\n",
    "        arcs = [(i, arc) for i, arc in enumerate(arcs) if arc.relation == 'SBV']\n",
    "\n",
    "        #print(\"\\t\".join(\"%d: %s\" % (arc[1].head, arc[1].relation) for arc in arcs))\n",
    "\n",
    "        for arc in arcs:\n",
    "            verb_index = arc[1].head  # Get the index of 说\n",
    "            subject_index = arc[0]  # Get the index of the subject who said\n",
    "            #print(subject_index)\n",
    "            if words[verb_index - 1] not in say:\n",
    "                continue\n",
    "            content.append((words[subject_index], words[verb_index - 1], ''.join(words[verb_index:])))\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech(data): # Get someone's speech from a data\n",
    "    result = list()\n",
    "    for i in split_sentences(data):\n",
    "        speech = who_say_what(i)\n",
    "        if speech != []:\n",
    "            result.extend(speech)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_from_file(file_name): # Get someone's speech from a file\n",
    "    result = list()\n",
    "    with open(file_name,'r+', encoding = 'utf-8') as file:\n",
    "        for line in file:\n",
    "            speech = who_say_what(line)\n",
    "            if speech != []:\n",
    "                result.extend(speech)\n",
    "    file.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "    “六一”国际儿童节前夕，习近平总书记向全国各族少年儿童致以节日祝贺，勉励他们刻苦学习知识，坚定理想信念，磨练坚强意志，锻炼强健体魄，为实现中华民族伟大复兴的中国梦时刻准备着。总书记的深情寄语凝聚着对少年儿童的真挚关怀和殷切期待，温暖激励广大少年儿童树立远大目标、努力学习知识本领，将来担当起民族复兴大任。\n",
    "\n",
    "六月一日是北京市高一、高二、初一、初二年级和小学六年级学生返校上课的第一天。回到久别的校园，学生们倍加珍惜时光，收到习爷爷的节日问候和祝福，让孩子们更是深受鼓舞。\n",
    "\n",
    "总书记指出，在这次全国人民万众一心抗击新冠肺炎疫情的斗争中，广大少年儿童听从党和政府号召以实际行动支持抗疫斗争，展现了我国少年儿童的良好精神风貌。在前期战“疫”艰难时刻，14岁的武汉女孩孙婉清给在一线奋战的父亲写下“没有一个冬天不可逾越”的家书，感动了亿万网友。\n",
    "\n",
    "习近平总书记指出，当代中国少年儿童既是实现第一个百年奋斗目标的经历者、见证者，更是实现第二个百年奋斗目标、建设社会主义现代化强国的生力军。培养好少年儿童是一项战略任务，事关长远。\n",
    "\n",
    "在新疆第一所民办国家通用语言小学——乌什县依麻木镇国语小学，孩子们正在收看“放飞梦想、快乐成长”主题诗歌朗诵，孩子们纷纷表达要倍加珍惜学习时光，为未来攀登科学高峰打好基础。\n",
    "\n",
    "在云南师范大学附属润城学校举行了“从小学先锋，长大做先锋”主题班会活动，积极引导学生爱国与奉献、担当与奋斗。\n",
    "\n",
    "在对少年儿童的寄语中，习近平总书记专门对共青团、少先队组织如何更好为党的少年儿童事业作出新的更大的贡献提出了明确要求。各级团组织认真学习领会总书记寄语精神，决心以深化改革的务实举措培养能够担当民族复兴大任的时代新人。\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('总书记', '指出', '，当代中国少年儿童既是实现第一个百年奋斗目标的经历者、见证者，更是实现第二个百年奋斗目标、建设社会主义现代化强国的生力军。')]\n"
     ]
    }
   ],
   "source": [
    "speech = get_speech(data)\n",
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#待优化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
