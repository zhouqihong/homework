{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.复习上课内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 回答一下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is independent assumption in Naive bayes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = black>朴素贝叶斯的独立假设是指给定类标签，样本的各个特征之间是相互独立的，即\n",
    "    $P(X = x|Y = y)=\\prod_{i=0}^nP(x_i|Y=y)$  \n",
    "    其中$x_i$是$x$的一个特征分量。\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is MAP(maximum a posterior) and ML(maximum likelihood) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于参数估计方法有两类：最大后验概率估计和极大似然估计。\n",
    "\n",
    "MAP假设模型参数是不确定的，参数源自一个潜在的分布，希望从数据中推知该分布，具体做法是不断调整模型参数使得模型能够产生该数据样本的概率最大。\n",
    "\n",
    "MLE假设模型参数是确定的，可以直接通过最大化数据样本的出现可能性来求出这个参数，没有先验估计，其结果完全依赖于观察的数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is support vector in SVM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持向量是指样本中距离超平面最近的一些数据点，分类的超平面是靠这些数据点来确定的。\n",
    "\n",
    "SVM思想：一些线性不可分的问题可能是非线性可分的，也就是在高维空间中存在分离超平面（separating hyperplane）\n",
    "使用非线性函数从原始的特征空间映射至更高维的空间，转化为线性可分问题\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the intuition behind SVM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM背后的直觉假设是数据是线性可分的（或可以通过非线性函数映射到线性可分的空间），可以通过一个超平面对数据空间进行切分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Shortly describ what 'random' means in random forest ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林是非常具有代表性的Bagging集成算法，它的所有基评估器都是决策树，分类树组成的森林就叫做随机森\n",
    "林分类器，回归树所集成的森林就叫做随机森林回归器。\n",
    "\n",
    "每一棵决策树的训练数据集是随机抽取的，而且特征也是随机抽取的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. What cariterion does XGBoost use to find the best split point in a tree ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost是串行生成CART树，但是XGBoost在处理特征时可以做到并行处理。在最优切分点的选择上，XGBoost首先根据每个特征大小对训练数据进行排序，保存为block结构，block个数与特征数量相等。然后对每个block结构选择最佳的特征切分点，节点切分标准是选择目标函数下降最大的点作为每个block结构的最佳切分点。最后比较每个block结构的最佳特征切分点的目标函数下降的增益，下降最大的切分点为最终的最佳切分点。\n",
    "\n",
    "参考\n",
    "https://baijiahao.baidu.com/s?id=1621144293288522535&wfr=spider&for=pc\n",
    "\n",
    "https://baijiahao.baidu.com/s?id=1621144293288522535&wfr=spider&for=pc%EF%BC%89\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Practial part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem description: In this part you are going to build a classifier to detect if a piece of news is published by the Xinhua news agency (新华社）."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Firstly, you have to come up with a way to represent the news. (Vectorize the sentence, you can find different ways to do so online)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Secondly,  pick a machine learning algorithm that you think is suitable for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38210</th>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社照片，外代，2017年4月23日\\n（外代二线）篮球——NBA季后赛：猛龙胜雄鹿\\n4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81321</th>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社照片，南昌，2017年5月31日\\n（体育）（2）“体操娃娃”的体育梦\\n倒立、压腿、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22248</th>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社北京４月９日电　２０１７年男子冰球世锦赛乙级Ｂ组９日在新西兰展开了第四轮的争夺，此...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81613</th>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社郑州５月３１日电（记者李丽静）记者３１日从河南省濮阳市华龙区人民法院获悉，该院２０...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40232</th>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社照片，外代，2017年4月25日\\n（外代二线）繁忙的新加坡港\\n4月24日，一艘货船...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                            content\n",
       "38210    新华社  新华社照片，外代，2017年4月23日\\n（外代二线）篮球——NBA季后赛：猛龙胜雄鹿\\n4...\n",
       "81321    新华社  新华社照片，南昌，2017年5月31日\\n（体育）（2）“体操娃娃”的体育梦\\n倒立、压腿、...\n",
       "22248    新华社  　　新华社北京４月９日电　２０１７年男子冰球世锦赛乙级Ｂ组９日在新西兰展开了第四轮的争夺，此...\n",
       "81613    新华社  　　新华社郑州５月３１日电（记者李丽静）记者３１日从河南省濮阳市华龙区人民法院获悉，该院２０...\n",
       "40232    新华社  新华社照片，外代，2017年4月25日\\n（外代二线）繁忙的新加坡港\\n4月24日，一艘货船..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/sqlResult_1558435.csv',encoding = 'gb18030')\n",
    "data = data[['source','content']]\n",
    "data = data.dropna()\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30873681ad9940ae8d77521a55cd4d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\Geoffrey\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.013 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#处理标签，新华社为1，其他为0\n",
    "labels = [1 if i =='新华社' else 0 for i in data['source']]\n",
    "#去掉特殊符号，只保留中英文\n",
    "texts = [re.sub('[^A-Za-z\\u4e00-\\u9fa5]','', sent) for sent in data['content']] \n",
    "#分词，因为数据集比较大，需要几分钟\n",
    "cut_texts = [' '.join(list(jieba.cut(sent))) for sent in tqdm_notebook(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集，后面5000条为数据测试集，其他为训练集\n",
    "train_data = cut_texts[:-5000]\n",
    "train_label = labels[:-5000]\n",
    "test_data = cut_texts[-5000:]\n",
    "test_label = labels[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用sklearn里的TfidfVectorizer工具对文本表示\n",
    "tfidf_model = TfidfVectorizer(max_df = 0.6, max_features =5000).fit(train_data) ## 词表太大，限制特征数为5000\n",
    "train_data = tfidf_model.transform(train_data)\n",
    "test_data = tfidf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=4,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#选择xgboost作为分类器进行训练\n",
    "model = XGBClassifier(n_jobs=4)\n",
    "model.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9526    0.9448    0.9487       489\n",
      "           1     0.9940    0.9949    0.9945      4511\n",
      "\n",
      "    accuracy                         0.9900      5000\n",
      "   macro avg     0.9733    0.9698    0.9716      5000\n",
      "weighted avg     0.9900    0.9900    0.9900      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查看测试结果\n",
    "pred_label = model.predict(test_data)\n",
    "print(classification_report(test_label,pred_label,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在二分类里，macro avg就是我们常说的精确率，召回率，F2分数。support 就是样本数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You have completed all assignments in this week. The question below is optional. If you still have time, why don't try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try differnt machine learning algorithms with different combinations of parameters in the practical part, and compare their performances (Better use some visualization techiniques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC()\n",
    "svc_model.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9381    0.8671    0.9012       489\n",
      "           1     0.9857    0.9938    0.9897      4511\n",
      "\n",
      "    accuracy                         0.9814      5000\n",
      "   macro avg     0.9619    0.9304    0.9455      5000\n",
      "weighted avg     0.9810    0.9814    0.9811      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_label = svc_model.predict(test_data)\n",
    "print(classification_report(test_label,pred_label,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100,n_jobs=4)# estimator：数据对象   n_jobs：同时工作的cpu个数（-1代表全部）\n",
    "rf_model.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9749    0.7955    0.8761       489\n",
      "           1     0.9783    0.9978    0.9879      4511\n",
      "\n",
      "    accuracy                         0.9780      5000\n",
      "   macro avg     0.9766    0.8966    0.9320      5000\n",
      "weighted avg     0.9779    0.9780    0.9770      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_label = rf_model.predict(test_data)\n",
    "print(classification_report(test_label,pred_label,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
